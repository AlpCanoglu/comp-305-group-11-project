{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# COMP305 -> 2-median problem on Optimal Placement of 2 Hospitals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import heapq\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "from random import choice\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"tests/test1_new.txt\") as f:\n",
    " #   test2 = f.read().splitlines()   \n",
    "\n",
    "#with open(\"tests/test2_new.txt\") as f:\n",
    " #   test2 = f.read().splitlines()   \n",
    "    \n",
    "#with open(\"tests/test3_new.txt\") as f:\n",
    "    #test3 = f.read().splitlines() \n",
    "    \n",
    "    \n",
    "#with open(\"tests/test1_aycan.txt\") as f:\n",
    " #   test01 = f.read().splitlines() \n",
    "    \n",
    "    \n",
    "#with open(\"tests/test_aycan.txt\") as f:\n",
    " #   test001 = f.read().splitlines() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# txt -> Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tests/test2_new.txt\") as f:\n",
    "    test2 = f.read().splitlines()   \n",
    "\n",
    "lines=test2\n",
    "\n",
    "number_of_vertices = int(lines[0])\n",
    "number_of_edges = int(lines[1])\n",
    "\n",
    "vertices = lines[2:2+number_of_vertices]\n",
    "edges = lines[2+number_of_vertices:]\n",
    "\n",
    "ids_and_populations = [tuple(map(int, vertices[i].split(\" \"))) for i in range(len(vertices))]\n",
    "populations = dict(sorted(dict(ids_and_populations).items())) #redundant sort\n",
    "\n",
    "mydict = lambda: defaultdict(lambda: defaultdict())\n",
    "G = mydict()\n",
    "\n",
    "for i in range(len(edges)):\n",
    "    source, target, weight = map(int, edges[i].split(\" \"))\n",
    "    G[source][target] = weight\n",
    "    G[target][source] = weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random spawned k-th neighbor Subgraph expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dijkstra_path(G, population_dict, source):\n",
    "    costs = dict()\n",
    "    for key in G:\n",
    "        costs[key] = np.inf\n",
    "    costs[source] = 0\n",
    "    #display(source,costs)\n",
    "\n",
    "    pq = []\n",
    "    for node in G:\n",
    "        heapq.heappush(pq, (node, costs[node]))\n",
    "\n",
    "    while len(pq) != 0:\n",
    "        current_node, current_node_distance = heapq.heappop(pq)\n",
    "        for neighbor_node in G[current_node]:\n",
    "            #print(current_node,costs[source])\n",
    "            weight = G[current_node][neighbor_node]\n",
    "            distance = current_node_distance + weight\n",
    "            if distance < costs[neighbor_node]:\n",
    "                #if source==neighbor_node:\n",
    "                    #print('here')\n",
    "                costs[neighbor_node] = distance\n",
    "                heapq.heappush(pq, (neighbor_node, distance))\n",
    "   \n",
    "    sorted_costs_lst=list(dict(sorted(costs.items())).values())\n",
    "    sorted_populations_lst = list(dict(sorted(population_dict.items())).values())\n",
    "    #print(np.array(sorted_costs_lst) ,np.array(sorted_populations_lst))\n",
    "    return np.array(sorted_costs_lst) * np.array(sorted_populations_lst)\n",
    "    #return list(dict(sorted(costs.items())).values())\n",
    "   \n",
    "   \n",
    "# V4 because runs in V^4\n",
    "def V4(G):\n",
    "\n",
    "    APSP = np.zeros((number_of_vertices,number_of_vertices))\n",
    "    population_dict = dict(sorted([(k, populations[k]) for k in G.keys()]))\n",
    "    for vertex in vertices:\n",
    "        vertex= int(vertex.split()[0])\n",
    "        APSP[vertex] = [e for e in dijkstra_path(G, population_dict,vertex)]\n",
    "\n",
    "    global glob\n",
    "\n",
    "    res = {}\n",
    "\n",
    "    n = len(APSP)\n",
    "   \n",
    "    temp_arr = APSP.copy()\n",
    "\n",
    "    count=0\n",
    "    count2=0\n",
    "    for first in range(n):\n",
    "        for second in range(first+1,n):\n",
    "            if first==second:\n",
    "                continue\n",
    "            count+=1\n",
    "            #print(count)\n",
    "            #print(first,second)\n",
    "            temp_arr = APSP.copy()\n",
    "            for row in temp_arr:\n",
    "                if row[first]<row[second]:\n",
    "                    row[second]=0\n",
    "                else:\n",
    "                    row[first]=0\n",
    "            #print(temp_arr,count)\n",
    "            to_be_summed = temp_arr[:,[first,second]]\n",
    "            summed = sum(sum(to_be_summed))\n",
    "            res[(first,second)]=summed\n",
    "    ret=min(res, key=res.get)\n",
    "    #display(len(res))\n",
    "    #display(res)\n",
    "    #print('pick {}th and {}th vertices to place hospitals!'.format(ret[0],ret[1]))\n",
    "    return ret, res[ret], res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vertex:\n",
    "\n",
    "    def __init__(self, id, weight):\n",
    "        self.key = 0\n",
    "        self.id = id\n",
    "        self.visited = False\n",
    "        self.weight = weight\n",
    "        self.neighbour_count = 0\n",
    "        self.neighbour_weight = 0\n",
    "        self.distance = 0\n",
    "        self.sum = 0\n",
    "        self.neighbour_neighbour_count = 0\n",
    "        self.neighbour_neighbour_weight = 0\n",
    "        self.neighbour_distance = 0\n",
    "        self.neighbour_sum = 0\n",
    "        self.neighbour_list = []\n",
    "        \n",
    "    def add_neighbour(self, Vertex, distance):\n",
    "        self.neighbour_list += [Vertex]\n",
    "        self.neighbour_count = self.neighbour_count + 1\n",
    "        self.distance = self.distance + distance\n",
    "        self.neighbour_weight = self.neighbour_weight + Vertex.weight\n",
    "        self.sum = self.sum + distance *  Vertex.weight\n",
    "        self.visited = True\n",
    "        \n",
    "    def add_neighbour_neighbour(self, Vertex):\n",
    "        self.neighbour_neighbour_count +=  Vertex.neighbour_count\n",
    "        self.neighbour_neighbour_weight += Vertex.neighbour_weight\n",
    "        self.neighbour_distance +=  Vertex.distance\n",
    "        self.neighbour_sum += Vertex.sum\n",
    "        self.visited = True\n",
    "\n",
    "    def calculate(self, a1, a2, a3):\n",
    "        self.key = self.weight *  a1 +  self.sum *  a2 +  self.neighbour_sum * a3   \n",
    "        return self.key\n",
    "\n",
    "    def get_key(self):\n",
    "        return self.key\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Key: \" + self.key.__str__() +  \" Id: \" + self.id.__str__() + \\\n",
    "        \" Visited: \" + self.visited.__str__() + \" Weight: \" + self.weight.__str__() +  \\\n",
    "        \" Neighbour_count: \" + self.neighbour_count.__str__() + \" Neighbour_weight: \" + self.neighbour_weight.__str__() + \\\n",
    "        \" Distance: \" + self.distance.__str__() + \" Sum: \" + self.sum.__str__() + \\\n",
    "        \" N_N_count: \" + self.neighbour_neighbour_count.__str__() + \" N_N_weight: \" + self.neighbour_neighbour_weight.__str__() + \\\n",
    "        \" N_Distance: \" + self.neighbour_distance.__str__() + \" N_Sum: \" + self.neighbour_sum.__str__() +  \"\\n\"\n",
    "    \n",
    "answer = V4(G)    \n",
    "    \n",
    "answer=answer[2]\n",
    "\n",
    "vertex_list = []\n",
    "\n",
    "for i in range(len(populations)):\n",
    "    v = Vertex(i, populations[i])\n",
    "    vertex_list += [v] \n",
    "\n",
    "for i in range(len(edges)):\n",
    "    index1, index2, distance = map(int, edges[i].split(\" \"))\n",
    "    v0 = vertex_list[index1]\n",
    "    v1 = vertex_list[index2]\n",
    "    v0.add_neighbour(v1, distance)\n",
    "    v1.add_neighbour(v0, distance)\n",
    "    \n",
    "\n",
    "for i in range(len(vertex_list)):\n",
    "    Vlist = vertex_list[i].neighbour_list\n",
    "    v0 = vertex_list[i]\n",
    "    for j in range(len(Vlist)):\n",
    "        v0.add_neighbour_neighbour(vertex_list[j])    \n",
    "        \n",
    "        \n",
    "        \n",
    "ret=answer[min(answer.keys())]\n",
    "ret_val=min(answer.keys())\n",
    "    \n",
    "dict2 = {}\n",
    "arr = []\n",
    "for (key, value) in answer.items():\n",
    "    dict2[value] = key\n",
    "    arr += [value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tests/test2_new.txt\") as f:\n",
    "    lines = f.read().splitlines()\n",
    "\n",
    "number_of_vertices = int(lines[0])\n",
    "number_of_edges = int(lines[1])\n",
    "\n",
    "vertices = lines[2:2+number_of_vertices]\n",
    "edges = lines[2+number_of_vertices:]\n",
    "\n",
    "ids_and_populations = [tuple(map(int, vertices[i].split(\" \"))) for i in range(len(vertices))]\n",
    "populations = dict(ids_and_populations)\n",
    "\n",
    "mydict = lambda: defaultdict(lambda: defaultdict())\n",
    "G = mydict()\n",
    "\n",
    "for i in range(len(edges)):\n",
    "    source, target, weight = map(int, edges[i].split(\" \"))\n",
    "    G[source][target] = weight\n",
    "    G[target][source] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_list = []\n",
    "\n",
    "for i in range(len(populations)):\n",
    "    v = Vertex(i, populations[i])\n",
    "    vertex_list += [v] \n",
    "\n",
    "for i in range(len(edges)):\n",
    "    index1, index2, distance = map(int, edges[i].split(\" \"))\n",
    "    v0 = vertex_list[index1]\n",
    "    v1 = vertex_list[index2]\n",
    "    v0.add_neighbour(v1, distance)\n",
    "    v1.add_neighbour(v0, distance)\n",
    "    \n",
    "\n",
    "for i in range(len(vertex_list)):\n",
    "    Vlist = vertex_list[i].neighbour_list\n",
    "    v0 = vertex_list[i]\n",
    "    for j in range(len(Vlist)):\n",
    "        v0.add_neighbour_neighbour(vertex_list[j])\n",
    "        \n",
    "        \n",
    "        \n",
    "ret=answer[min(answer.keys())]\n",
    "ret_val=min(answer.keys())\n",
    "    \n",
    "dict2 = {}\n",
    "arr = []\n",
    "for (key, value) in answer.items():\n",
    "    dict2[value] = key\n",
    "    arr += [value]\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1.0e-8\n",
    "epochs = 10\n",
    "bias = 1\n",
    "sum = 0\n",
    "\n",
    "def Preceptator(Vertex1, Vertex2, a1, a2, a3, output):\n",
    "    outputP = Vertex1.calculate(a1, a2, a3) + Vertex2.calculate(a1, a2, a3)\n",
    "\n",
    "    error1 = learning_rate * (output - outputP) * a1 \n",
    "    error2 = learning_rate * (output - outputP) * a2\n",
    "    error3 = learning_rate * (output - outputP) * a3\n",
    "\n",
    "    a1 += error1\n",
    "    a2 += error2\n",
    "    a3 += error3\n",
    "    return abs(output - outputP)\n",
    "\n",
    "def getClosestValue(k):\n",
    "    b = int(k)\n",
    "    lst = list(range(b - 1, b + 2, 1))  # lst = [b-1,b,b+1]\n",
    "    return lst[min(range(len(lst)), key=lambda i: abs(lst[i] - k))]\n",
    "\n",
    "def Predict(Vertex1, Vertex2, a1, a2, a3):\n",
    "    value = Vertex1.calculate(a1, a2, a3) + Vertex2.calculate(a1, a2, a3)\n",
    "    if (value < 0):\n",
    "        print(\"value : \", int(value) - 1)\n",
    "    elif value == 0:\n",
    "        print(\"value : \", value)\n",
    "    else:\n",
    "        print(\"value : \", int(value))\n",
    "    print(\"y  =  \", getClosestValue(w[0]), \" + \", getClosestValue(w[1]), \" * x1 + \", getClosestValue(w[2]), \" * x2\")\n",
    "    \n",
    "def calculate(Vertex, a1, a2, a3, a4, a5, a6, a7, a8, a9):\n",
    "    return Vertex.weight *  a1 +  Vertex.neighbour_count * a2 + \\\n",
    "    Vertex.neighbour_weight *  a3 +  Vertex.distance * a4 + \\\n",
    "    Vertex.sum *  a5 +  Vertex.neighbour_neighbour_count * a6 + \\\n",
    "    Vertex.neighbour_neighbour_weight *  a7 +  Vertex.neighbour_distance * a8 + \\\n",
    "    Vertex.neighbour_sum * a9\n",
    "    \n",
    "def sigmoid(X, w, w0):\n",
    "    return (1 / (1 + np.exp(-(np.matmul(X, w) + w0))))\n",
    "\n",
    "\n",
    "def gradient_W(X, y_truth, y_predicted):\n",
    "    return (np.asarray(\n",
    "        [-np.sum(np.repeat((y_truth[:, c] - y_predicted[:, c])[:, None], X.shape[1], axis=1) * X, axis=0) for c in\n",
    "         range(K)]).transpose()) / 3\n",
    "\n",
    "def gradient_w0(Y_truth, Y_predicted):\n",
    "    return (-np.sum(Y_truth - Y_predicted, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training sets\n",
    "#for i in range(epochs):\n",
    "a1 = np.random.rand(1) * 100 \n",
    "a2 = np.random.rand(1) * 10 \n",
    "a3 = np.random.rand(1) * 1 \n",
    "count = 0\n",
    "\n",
    "for i in range(len(vertex_list)):\n",
    "    for j in range(int(len(vertex_list))):   \n",
    "        if i>j:       \n",
    "            v0 = vertex_list[i]\n",
    "            v1 = vertex_list[j]\n",
    "            value = arr[count]\n",
    "            count += 1\n",
    "            for j in range(epochs):\n",
    "                val = Preceptator(v0, v1, a1, a2, a3, value)\n",
    "                if j == epochs-1:\n",
    "                    sum += val\n",
    "            \n",
    "print(sum/(count)/max(arr))\n",
    "\n",
    "\n",
    "#Normalizing the variables\n",
    "coef_sum = a1 + a2 + a3\n",
    "a1 = a1 / coef_sum\n",
    "a2 = a2 / coef_sum\n",
    "a3 = a3 / coef_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"tests/test3_new.txt\") as f:\n",
    "    #lines = f.read().splitlines()\n",
    "    \n",
    "with open(\"tests/test3_new.txt\") as f:\n",
    "    lines = f.read().splitlines()\n",
    "\n",
    "\n",
    "number_of_vertices = int(lines[0])\n",
    "number_of_edges = int(lines[1])\n",
    "\n",
    "vertices = lines[2:2+number_of_vertices]\n",
    "edges = lines[2+number_of_vertices:]\n",
    "\n",
    "ids_and_populations = [tuple(map(int, vertices[i].split(\" \"))) for i in range(len(vertices))]\n",
    "populations = dict(ids_and_populations)\n",
    "\n",
    "mydict = lambda: defaultdict(lambda: defaultdict())\n",
    "G = mydict()\n",
    "\n",
    "for i in range(len(edges)):\n",
    "    source, target, weight = map(int, edges[i].split(\" \"))\n",
    "    G[source][target] = weight\n",
    "    G[target][source] = weight\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "\n",
    "vertex_list = []\n",
    "for i in range(len(populations)):\n",
    "    v = Vertex(i, populations[i])\n",
    "    vertex_list += [v] \n",
    "\n",
    "for i in range(len(edges)):\n",
    "    index1, index2, distance = map(int, edges[i].split(\" \"))\n",
    "    v0 = vertex_list[index1]\n",
    "    v1 = vertex_list[index2]\n",
    "    v0.add_neighbour(v1, distance)\n",
    "    v1.add_neighbour(v0, distance)\n",
    "    \n",
    "\n",
    "for i in range(len(vertex_list)):\n",
    "    Vlist = vertex_list[i].neighbour_list\n",
    "    v0 = vertex_list[i]\n",
    "    for j in range(len(Vlist)):\n",
    "        v0.add_neighbour_neighbour(vertex_list[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = 92.72\n",
    "a2 = 9.87\n",
    "a3 = 0.89\n",
    "\n",
    "for i in range(len(vertex_list)):    \n",
    "    v0 = vertex_list[i]\n",
    "    v0.calculate(a1, a2, a3)\n",
    "    \n",
    "K_arr = []\n",
    "for i in range(len(vertex_list)):        \n",
    "    K_arr += [vertex_list[i].get_key()]\n",
    "\n",
    "min_val = min(K_arr) \n",
    "K_arr.sort()\n",
    "index1 = 0\n",
    "index2 = 0\n",
    "\n",
    "for i in range(len(vertex_list)):\n",
    "    v = vertex_list[i]\n",
    "    if K_arr[0] == v.get_key():\n",
    "        index1 = i\n",
    "    if K_arr[1] == v.get_key():\n",
    "        index2 = i\n",
    "    \n",
    "\n",
    "diff = time.time()-start\n",
    "\n",
    "\n",
    "\n",
    "print('time took: '+str(diff))\n",
    "print('first node:{}, second node:{} ; associated cost:{}'.format(index1,index2,min_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_neighbors(G, sub_graph, current_node, k):\n",
    "    if k == 0:\n",
    "        return sub_graph\n",
    "\n",
    "    for j in G[current_node].items():\n",
    "        sub_graph[current_node][j[0]] = j[1]\n",
    "        sub_graph[j[0]][current_node] = j[1]\n",
    "\n",
    "        sub_graph = select_neighbors(G, sub_graph, j[0], k - 1)\n",
    "    return sub_graph\n",
    "\n",
    "\n",
    "def merge_graph(dict1, dict2):\n",
    "    for key, value in dict2.items():\n",
    "        for subkey, subvalue in value.items():\n",
    "            dict1[key][subkey] = subvalue\n",
    "\n",
    "\n",
    "def dijkstra_q_impl(G, populations, source): \n",
    "    costs = dict()\n",
    "    for key in G:\n",
    "        costs[key] = np.inf\n",
    "    costs[source] = 0\n",
    "\n",
    "    pq = []\n",
    "    for node in G:\n",
    "         pq.append((node, costs[node]))\n",
    "\n",
    "    while len(pq) != 0:\n",
    "        current_node, current_node_distance = pq.pop(0)\n",
    "        for neighbor_node in G[current_node]:\n",
    "            weight = G[current_node][neighbor_node]\n",
    "            distance = current_node_distance + weight\n",
    "            if distance < costs[neighbor_node]:\n",
    "                costs[neighbor_node] = distance\n",
    "                pq.append((neighbor_node, distance))\n",
    "    \n",
    "    #return (costs.values(),population_dict[])\n",
    "    sorted_costs_lst=list(dict(sorted(costs.items())).values())\n",
    "    populations_values_lst = list(dict(sorted(populations.items())).values())\n",
    "    return np.sum(np.array(sorted_costs_lst) * np.array(populations_values_lst))\n",
    "\n",
    "def random_start(G):\n",
    "    res = [choice(list(G.keys())), choice(list(G.keys()))]\n",
    "    if res[0] == res [1]:\n",
    "        return random_start(G)\n",
    "    print(f\"Random start: {res}\")\n",
    "    return res\n",
    "    #return [929940, 301820]\n",
    "\n",
    "\n",
    "#//2 * O((V+E)*logV) = O(E*logV) // \n",
    "def allocation_cost(G, population_dict, i,j):\n",
    "    return [dijkstra_q_impl(G,population_dict, i),dijkstra_q_impl(G,population_dict, j)]\n",
    "\n",
    "\n",
    "# V times Dijkstra\n",
    "def sub_graph_apsp(G, dijkstra_func):\n",
    "    population_dict = dict(sorted([(k, populations[k]) for k in G.keys()]))\n",
    "    selected_vertex = choice(list(G.keys()))\n",
    "    selected_cost = dijkstra_func(G,population_dict, selected_vertex)\n",
    "    \n",
    "    for node in G.keys():\n",
    "        if node is not selected_vertex:\n",
    "            this_cost = dijkstra_func(G, population_dict, node) \n",
    "            if this_cost < selected_cost:\n",
    "                selected_cost = this_cost\n",
    "                selected_vertex = node    \n",
    "    return selected_vertex, selected_cost\n",
    "\n",
    "\n",
    "def algorithm_sub_graph_apsp(G, starting_node, k, hop_list, dijkstra_func):\n",
    "    sub_graph = lambda: defaultdict(lambda: defaultdict())\n",
    "    sub_graph = sub_graph()\n",
    "    sub_graph = select_neighbors(G, sub_graph, current_node=starting_node, k=k)\n",
    "    next_node, cost = sub_graph_apsp(sub_graph, dijkstra_func)\n",
    "    #print(next_node)\n",
    "    \n",
    "    if len(hop_list) > 0 and next_node == hop_list[-1][0]:\n",
    "        return next_node, cost\n",
    "    \n",
    "    hop_list.append((next_node, cost))\n",
    "    return algorithm_sub_graph_apsp(G, next_node, k, hop_list, dijkstra_func)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2*O(V)*O(E*logV) = O(E*V*logV) #\n",
    "def Greedy_Heuristic_Add_Drop(G, dijkstra_func):\n",
    "    population_dict = dict(sorted([(k, populations[k]) for k in G.keys()]))\n",
    "    #population_dict = [populations[i] for i in G.keys()]\n",
    "    selected_vertices = random_start(G) \n",
    "    selected_costs = allocation_cost(G,population_dict, selected_vertices[0],selected_vertices[1])\n",
    "    \n",
    "    for not_selected in G.keys():\n",
    "        if not_selected not in selected_vertices:\n",
    "            bigger = max(selected_costs)\n",
    "            this_cost = dijkstra_func(G,population_dict, not_selected) \n",
    "            if this_cost < bigger:\n",
    "                bigger_index = selected_costs.index(bigger)\n",
    "                selected_costs[bigger_index] = this_cost\n",
    "                selected_vertices[bigger_index] = not_selected\n",
    "    return(selected_vertices,selected_costs)\n",
    "\n",
    "\n",
    "def Greedy_Heuristic_Subgraph_Expansion(G, k, dijkstra_func, bootstrap_cnt=10):\n",
    "    nodes = []\n",
    "    costs = []\n",
    "    \n",
    "    for i in range(bootstrap_cnt):\n",
    "        #print(\"iter\")\n",
    "        node, cost = algorithm_sub_graph_apsp(G, choice(list(G.keys())), k, [], dijkstra_func=dijkstra_func)\n",
    "        nodes.append(node)\n",
    "        costs.append(cost)\n",
    "        \n",
    "    counter = Counter(nodes)\n",
    "    most_commons = counter.most_common(2)\n",
    "    target_nodes = (most_commons[0][0], most_commons[1][0])\n",
    "    \n",
    "    sub_graph1 = lambda: defaultdict(lambda: defaultdict())\n",
    "    sub_graph1 = sub_graph1()\n",
    "    sub_graph1 = select_neighbors(G, sub_graph1, target_nodes[0], k=k)\n",
    "    \n",
    "    sub_graph2 = lambda: defaultdict(lambda: defaultdict())\n",
    "    sub_graph2 = sub_graph2()\n",
    "    sub_graph2 = select_neighbors(G, sub_graph2, target_nodes[1], k=k)\n",
    "\n",
    "    merge_graph(sub_graph1, sub_graph2)\n",
    "\n",
    "    points, costs = Greedy_Heuristic_Add_Drop(sub_graph1, dijkstra_func)\n",
    "\n",
    "    if np.inf in costs:\n",
    "        print(\"INF\")\n",
    "        sub_graph1 = lambda: defaultdict(lambda: defaultdict())\n",
    "        sub_graph1 = sub_graph1()\n",
    "        sub_graph1 = select_neighbors(G, sub_graph1, current_node=points[0], k=k+1)\n",
    "        \n",
    "        sub_graph2 = lambda: defaultdict(lambda: defaultdict())\n",
    "        sub_graph2 = sub_graph2()\n",
    "        sub_graph2 = select_neighbors(G, sub_graph2, current_node=points[1], k=k+1)\n",
    "        \n",
    "        merge_graph(sub_graph1, sub_graph2)\n",
    "        \n",
    "        \n",
    "\n",
    "        points, costs = Greedy_Heuristic_Add_Drop(sub_graph1, dijkstra_func)\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "        if np.inf not in costs:\n",
    "            return points, costs\n",
    "        else:\n",
    "            print(\"Graphs are disconnected. Total cost is inf\")\n",
    "            return points, costs\n",
    "    return points, costs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start = time.time()\n",
    "\n",
    "res = Greedy_Heuristic_Subgraph_Expansion(G, 5, bootstrap_cnt=10, dijkstra_func=dijkstra_q_impl) #q for direct Queue based PQ impl (py's pop(0))\n",
    "\n",
    "diff = time.time()-start\n",
    "\n",
    "print('\\npick cities #'+  str(res[0]) +' with costs '+ str(res[1]))\n",
    "print('\\ntotal time using our Queue-based PQ: '+ str(diff)+ ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
